{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d555fb-a1b1-4a3c-a430-0271a74095c7",
   "metadata": {},
   "source": [
    "The objective of this notebook is transforming a folder filled with images into FGSM-modified cover images following the approaches shown in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a6ac7-a08c-4f2d-884e-a63db56a35a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "705bfd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe17831",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fast Gradient Sign Method (FGSM)\n",
    "\n",
    "FGSM is a white box attack is that one that is performed by an attacker that has access to the whole model.\n",
    "\n",
    "This method was presented in the [Explaining and Harnessing Adversarial Examples by Ian Goodfellow et al.](https://arxiv.org/abs/1412.6572). It consists on using the gradients of the loss with respect to the input image to create a new image that maximizes the loss. The new image generated is the adversarial image. The following expression summarizes everything:\n",
    "\n",
    "\\begin{align}\n",
    "adv_{-} x=x+\\epsilon * \\operatorname{sign}\\left(\\nabla_{x} J(\\theta, x, y)\\right)\n",
    "\\end{align}\n",
    "\n",
    "The gradients are taken with respect to the input image because the objective is to check how much each pixel of the image contributes to the loss value.\n",
    "\n",
    "As mentioned in the title of this Notebook, this is a white box attack. Some other [more advanced approaches](https://arxiv.org/abs/1602.02697) have been taken using FGSM from a Black Box perspective. However, this is much more complex.\n",
    "\n",
    "The code used below is based in [the implementation of the Official Tensorflow Page](https://www.tensorflow.org/tutorials/generative/adversarial_fgsm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e4ac31-db18-4a8e-a6c9-bcc47a208f93",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "The model used in this notebook is the available in the [SRNet-Tensorflow-Implementation](https://github.com/davidggz/SRNet-Tensorflow-Implementation) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d80af1f-00bd-480a-81fe-783dcba9818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'model_checkpoint/best_model.h5'\n",
    "IMAGE_DIR = 'Path to the folder with cover and stego images'\n",
    "OUTPUT_DIR = 'Name or path of the output folder'\n",
    "EPSILON = 0.01\n",
    "\n",
    "# Loss that will be used to calculate the gradient. This loss must change \n",
    "# in case softmax is used as the output activation function.\n",
    "LOSS_OBJECT = tf.keras.losses.BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0b996-4a30-435f-a82d-945a6157f973",
   "metadata": {},
   "source": [
    "## Load the model to be attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5fbaa1a-6889-4cd1-a58c-872882e21637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# Don't allow training the model\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070b915-2c60-4c73-885c-a4b7dd86140d",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9e86d1-4b6c-4008-a47f-19ca685ef1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    # Scale the image so that it's in the range 0-1.\n",
    "    image = image * 1./255\n",
    "    return image\n",
    "\n",
    "\n",
    "def read_and_preprocess_image(image_filename):\n",
    "    # Read the image not changing any pixel\n",
    "    image = cv2.imread(image_filename, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Expand the dimensions to have a shape (1, N, M, 1)\n",
    "    image = np.expand_dims(image, axis=(0, 3))\n",
    "    \n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocessing(image)\n",
    "    \n",
    "    return preprocessed_image\n",
    "    \n",
    "\n",
    "# This is just a FGSM implementation\n",
    "def create_adversarial_pattern(input_image, input_label):\n",
    "    ''' This function receives a [-1, 1] image and it returns \n",
    "    the direction that we need to go in each pixel in order to \n",
    "    go far from the input_label\n",
    "    '''\n",
    "    # Transform the input image into a tensor\n",
    "    tf_image = tf.convert_to_tensor(input_image, dtype=tf.float32)\n",
    "    \n",
    "    # Expand the dimensions to have shape (1, 1)\n",
    "    input_label = np.expand_dims(input_label, axis=(0, 1))\n",
    "    \n",
    "    # Initialize GradientTape store the interaction of the input with the model\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Indicate that we want to be aware of tf_image\n",
    "        tape.watch(tf_image)\n",
    "        \n",
    "        # Make the prediction and get the loss\n",
    "        prediction = model(tf_image)\n",
    "        loss = LOSS_OBJECT(input_label, prediction)\n",
    "\n",
    "    # Once we have the loss and we've stored in the tape everything that happened during the inference,\n",
    "    # we can check the gradient with respect to any variable or constant. In this case,\n",
    "    # the gradient is obtained with respecto to the image itself.\n",
    "    gradient = tape.gradient(loss, tf_image)\n",
    "    \n",
    "    # We get just the sign of the gradient.\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    \n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19300ed3-98e5-4060-877f-e6b63225ea9b",
   "metadata": {},
   "source": [
    "## fromCover algorithm\n",
    "\n",
    "As it is stated in the repository description, this algorithm takes the cover images and it generates its FGSM-modified versions by using the cover image itself as the input of the FGSM algorithm. Once the FGSM-modified images have been generated, it is necessary to introduce the stego message into the images. These images will be prepared to attack a determined SRNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ae39b7e-0b08-48bc-a882-6b5674fc4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the folders necessary to train and test.\n",
    "assert not os.path.isdir(OUTPUT_DIR)\n",
    "os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "sets = ['train', 'val']\n",
    "for set_name in sets:\n",
    "    os.mkdir(os.path.join(OUTPUT_DIR, set_name))\n",
    "    os.mkdir(os.path.join(OUTPUT_DIR, set_name, '0'))\n",
    "    os.mkdir(os.path.join(OUTPUT_DIR, set_name, '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2761392a-f87c-4c32-a34e-4c15b68d70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the images to transform\n",
    "all_original_fullpaths = glob.glob(os.path.join(IMAGE_DIR, '*', '*',  '*'))\n",
    "\n",
    "# Transform every image in the directory\n",
    "for original_fullpath in all_original_fullpaths:\n",
    "    # Get the input label from the name of the directory\n",
    "    input_label = int(original_fullpath.split('\\\\')[-2])\n",
    "    \n",
    "    # Read and preprocess the image\n",
    "    preprocessed_image = read_and_preprocess_image(original_fullpath)\n",
    "    \n",
    "    # Change the image to be in the range [-1, 1]\n",
    "    preprocessed_image = preprocessed_image * 2 - 1\n",
    "    \n",
    "    # Get the perturbations\n",
    "    perturbations = create_adversarial_pattern(preprocessed_image, input_label)\n",
    "    \n",
    "    # Transform the input image with the perturbations\n",
    "    adversarial_image = preprocessed_image + EPSILON * perturbations\n",
    "    \n",
    "    # Remove those values that are below -1 or above 1\n",
    "    adversarial_image = tf.clip_by_value(adversarial_image, -1, 1)\n",
    "    \n",
    "    # Transform the image back again into the range [0, 255]\n",
    "    adversarial_image = (adversarial_image * 0.5 + 0.5) * 255\n",
    "    \n",
    "    # Transform to numpy and reshape\n",
    "    adversarial_image = np.reshape(adversarial_image.numpy(), (256, 256))\n",
    "    \n",
    "    # Store the image in OUTPUT_DIR\n",
    "    out_fullpath = os.path.join(OUTPUT_DIR, original_fullpath.split('\\\\')[-3], str(input_label), original_fullpath.split('\\\\')[-1])\n",
    "    cv2.imwrite(out_fullpath, adversarial_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dd25e0-8736-4b23-bd4c-3d35c1d7ceb2",
   "metadata": {},
   "source": [
    "## fromStego algorithm\n",
    "\n",
    "This is an algorithm similar to the previous one. However, in this case the stego images are necessary since the FGSM perturbations to be applied to the cover images are obtained from the stego images. Once the cover images have been modified, the hidden message has to be added again to the FGSM-modified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "141be40a-9292-492a-b9e0-3f5d36d94c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory\n",
    "assert not os.path.isdir(OUTPUT_DIR)\n",
    "os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "os.mkdir(os.path.join(OUTPUT_DIR, '0'))\n",
    "os.mkdir(os.path.join(OUTPUT_DIR, '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc502b2-268b-44c6-bba0-f010178715d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the images to transform\n",
    "cover_full_filenames = glob.glob(os.path.join(IMAGE_DIR, '0', '*'))\n",
    "stego_full_filenames = glob.glob(os.path.join(IMAGE_DIR, '1', '*'))\n",
    "\n",
    "# Transform every image in the directory\n",
    "for cover_full_filename, stego_full_filename in zip(cover_full_filenames, stego_full_filenames):\n",
    "    # In this case the input label is always 1 because we are obtaining\n",
    "    # the perturbations from the stego images.\n",
    "    input_label = 1\n",
    "    \n",
    "    # Read and preprocess the image\n",
    "    cover_preprocessed_image = read_and_preprocess_image(cover_full_filename)\n",
    "    stego_preprocessed_image = read_and_preprocess_image(stego_full_filename)\n",
    "    \n",
    "    # Change the image to be in the range [-1, 1]\n",
    "    cover_preprocessed_image = cover_preprocessed_image * 2 - 1\n",
    "    stego_preprocessed_image = stego_preprocessed_image * 2 - 1\n",
    "    \n",
    "    # Get the perturbations\n",
    "    perturbations = create_adversarial_pattern(stego_preprocessed_image, input_label)\n",
    "    \n",
    "    # Transform the input image with the perturbations\n",
    "    adversarial_image = cover_preprocessed_image + EPSILON * perturbations\n",
    "    \n",
    "    # Remove those values that are below -1 or above 1\n",
    "    adversarial_image = tf.clip_by_value(adversarial_image, -1, 1)\n",
    "    \n",
    "    # Transform the image back again into the range [0, 255]\n",
    "    adversarial_image = (adversarial_image * 0.5 + 0.5) * 255\n",
    "    \n",
    "    # Transform to numpy and reshape\n",
    "    adversarial_image = np.reshape(adversarial_image.numpy(), (256, 256))\n",
    "    \n",
    "    # Store the image in OUTPUT_DIR\n",
    "    out_fullpath = os.path.join(OUTPUT_DIR, '0', cover_full_filename.split('\\\\')[-1])\n",
    "    cv2.imwrite(out_fullpath, adversarial_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
